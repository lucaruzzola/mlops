{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Presented by Aim2](aim2.png)](https://www.youtube.com/watch?v=p4z2FDSfZb4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Machine Learning Workflow\n",
    "![MLworkflow](ml_workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing the complex ML lifecycle with\n",
    "![MLFLow](MLFlow-logo-final-black-50.png)\n",
    "## Three components: Tracking, Projects, Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MLflow Tracking component is an API and UI for logging parameters, code versions, metrics, and output files when running your machine learning code and for later visualizing the results. MLflow Tracking lets you log and query experiments using both Python and REST APIs.\n",
    "\n",
    "By default, wherever you run your program, the tracking API writes data into files into an mlruns directory. You can then run MLflow’s Tracking UI:\n",
    "\n",
    "*mlflow ui*\n",
    "\n",
    "and view it at http://localhost:5000\n",
    "\n",
    "Alternatively, you can configure MLflow to log runs to a remote server to manage your results centrally or share them across a team.\n",
    "\n",
    "The MLflow Tracking API lets you log metrics and artifacts (files) from your data science code and see a history of your runs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mlflow import log_metric, log_param, log_artifact\n",
    "import random\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    # Log a parameter (key-value pair)\n",
    "    log_param(\"param1\", 5)\n",
    "\n",
    "    # Log a metric; metrics can be updated throughout the run\n",
    "    log_metric(\"foo\", 1)\n",
    "    log_metric(\"foo\", 2)\n",
    "    log_metric(\"foo\", 3)\n",
    "\n",
    "\n",
    "    # Log an artifact (output file)\n",
    "    with open(\"output.txt\", \"w\") as f:\n",
    "        f.write(\"Hello world!\")\n",
    "    log_artifact(\"output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mock_loss(min_x, max_x):\n",
    "    for x in range(min_x, max_x):\n",
    "        y = 1/x\n",
    "        random_factor = 0.2\n",
    "        yield y*random.uniform(1 - random_factor, 1 + random_factor)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    #log the value of a function (e.g. a loss function)\n",
    "    num_steps = 10\n",
    "    mlflow.log_param(\"num_steps\",num_steps)\n",
    "    for y in mock_loss(1,num_steps):\n",
    "        log_metric(\"loss_function\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import mlflow.sklearn\n",
    "\n",
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "np.random.seed(40)\n",
    "\n",
    "# Read the wine-quality csv file (make sure you're running this from the root of MLflow!)\n",
    "wine_path = \"/Users/luca/mlops/sklearn_elasticnet_wine/wine-quality.csv\"\n",
    "data = pd.read_csv(wine_path)\n",
    "\n",
    "# Split the data into training and test sets. (0.75, 0.25) split.\n",
    "train, test = train_test_split(data)\n",
    "\n",
    "# The predicted column is \"quality\" which is a scalar from [3, 9]\n",
    "train_x = train.drop([\"quality\"], axis=1)\n",
    "test_x = test.drop([\"quality\"], axis=1)\n",
    "train_y = train[[\"quality\"]]\n",
    "test_y = test[[\"quality\"]]\n",
    "\n",
    "def train_wine_regression(alpha, l1_ratio,exp_id):\n",
    "    mlflow.set_experiment(exp_id)\n",
    "    with mlflow.start_run():\n",
    "        lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
    "        lr.fit(train_x, train_y)\n",
    "\n",
    "        predicted_qualities = lr.predict(test_x)\n",
    "\n",
    "        (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n",
    "\n",
    "        print(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n",
    "        print(\"  RMSE: %s\" % rmse)\n",
    "        print(\"  MAE: %s\" % mae)\n",
    "        print(\"  R2: %s\" % r2)\n",
    "\n",
    "        mlflow.log_param(\"alpha\", alpha)\n",
    "        mlflow.log_param(\"l1_ratio\", l1_ratio)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "\n",
    "        mlflow.sklearn.log_model(lr, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 'wine' does not exist. Creating a new experiment\n",
      "Elasticnet model (alpha=0.100000, l1_ratio=1.900000):\n",
      "  RMSE: 0.8008614421065388\n",
      "  MAE: 0.6215339293635124\n",
      "  R2: 0.17161039226431196\n"
     ]
    }
   ],
   "source": [
    "train_wine_regression(alpha=0.1, l1_ratio=1.9, exp_id=\"wine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticnet model (alpha=0.200000, l1_ratio=1.770000):\n",
      "  RMSE: 0.8442722944179337\n",
      "  MAE: 0.638440439200057\n",
      "  R2: 0.07937037119958534\n"
     ]
    }
   ],
   "source": [
    "train_wine_regression(alpha=0.2, l1_ratio=1.77, exp_id=\"wine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log on remote server\n",
    "It's possible to log to a remote server, setting the server URI as:\n",
    "\n",
    "*mlflow.set_tracking_uri(URI)*\n",
    "\n",
    "And an mlflow server can be simply started via:\n",
    "\n",
    "*mlflow server \n",
    "    --file-store /mnt/persistent-disk \n",
    "    --default-artifact-root s3://my-mlflow-bucket/ \n",
    "    --host 0.0.0.0*\n",
    "    \n",
    "The file store (exposed as --file-store) is where the server stores run and experiment metadata. It defaults to the local ./mlruns directory (the same as when running mlflow run locally), but when running a server, make sure that this points to a persistent (that is, non-ephemeral) file system location.\n",
    "\n",
    "The artifact store is a location suitable for large data (such as an S3 bucket or shared NFS file system) and is where clients log their artifact output (for example, models). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projects\n",
    "MLflow Projects are a standard format for packaging reusable data science code. Each project is simply a directory with code or a Git repository, and uses a descriptor file to specify its dependencies and how to run the code. For example, projects can contain a conda.yaml file for specifying a Python Conda environment. When you use the MLflow Tracking API in a Project, MLflow automatically remembers the project version executed (for example, Git commit) and any parameters. \n",
    "### MLProject\n",
    "name: tutorial\n",
    "\n",
    "conda_env: conda.yaml\n",
    "\n",
    "entry_points:\n",
    "  main:\n",
    "    parameters:\n",
    "      alpha: float\n",
    "      l1_ratio: {type: float, default: 0.1}\n",
    "    command: \"python train.py {alpha} {l1_ratio}\"\n",
    "\n",
    "### Conda yaml\n",
    "name: tutorial\n",
    "channels:\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - numpy=1.14.3\n",
    "  - pandas=0.22.0\n",
    "  - scikit-learn=0.19.1\n",
    "  - pip:\n",
    "    - mlflow\n",
    "    \n",
    "*mlflow run sklearn_elasticnet_wine/ -P alpha=0.42 -P l1_ratio=0.2* --experiment-id xxx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "MLflow Models offer a convention for packaging machine learning models in multiple flavors, and a variety of tools to help you deploy them. Each Model is saved as a directory containing arbitrary files and a descriptor file that lists several “flavors” the model can be used in. For example, a TensorFlow model can be loaded as a TensorFlow DAG, or as a Python function to apply to input data. MLflow provides tools to deploy many common model types to diverse platforms: for example, any model supporting the “Python function” flavor can be deployed to a Docker-based REST server, to cloud platforms such as Azure ML and AWS SageMaker, and as a user-defined function in Apache Spark for batch and streaming inference. \n",
    "\n",
    "mlflow pyfunc serve -m /Users/luca/mlops/mlruns/1/a88084eb6dbd418bbe6aa55167089274/artifacts/model -p 1234\n",
    "\n",
    "curl -X POST -H \"Content-Type:application/json; format=pandas-split\" --data '{\"columns\":[\"alcohol\", \"chlorides\", \"citric acid\", \"density\", \"fixed acidity\", \"free sulfur dioxide\", \"pH\", \"residual sugar\", \"sulphates\", \"total sulfur dioxide\", \"volatile acidity\"],\"data\":[[12.8, 0.029, 0.48, 0.98, 6.2, 29, 3.33, 1.2, 0.39, 75, 0.66]]}' http://127.0.0.1:1234/invocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
